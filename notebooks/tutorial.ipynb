{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from temed_llm.nlp.chat_model import create_llm\n",
    "from temed_llm.data.data_schema import load_schema\n",
    "from temed_llm.data.prompts import load_prompt\n",
    "from temed_llm.core.rextract import RExtract\n",
    "from temed_llm.utils.utils import setup_logger\n",
    "from temed_llm.core.vorc import VORC\n",
    "# from temed_llm.utils.config import dataset_name, openai_api_key\n",
    "\n",
    "logger = setup_logger(\"INFO\")\n",
    "\n",
    "\n",
    "def main(dataset_names):\n",
    "    for dataset_name in dataset_names:\n",
    "        llm = create_llm(\"meta-llama/Llama-2-70b-chat-hf\")\n",
    "        temp = pd.read_csv(dataset_name)\n",
    "        sample_size = min(150, len(temp))\n",
    "        df = temp.sample(sample_size)\n",
    "\n",
    "        # Load the appropriate prompt & schema for the given dataset_name\n",
    "        pydantic_schema = load_schema(dataset_name)\n",
    "        vorc_object = VORC(pydantic_object=pydantic_schema)\n",
    "\n",
    "        prompt = load_prompt(dataset_name)\n",
    "        prompt = prompt.replace(\"{pydantic_output_parser}\", vorc_object.get_format_instructions())\n",
    "\n",
    "        processor = RExtract(llm, vorc_object, prompt)\n",
    "\n",
    "        checkpoint_file = f\"{dataset_name.split('.')[0]}_checkpoint.csv\"  # you may also prepend a directory if needed, like ./checkpoints/\n",
    "\n",
    "        processor.process_dataframe(df, checkpoint_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the function with the desired dataset names\n",
    "    main([\"treatment.csv\", \"heart.csv\"])  # \"stroke.csv\",\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
